{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data/sst2.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[\"x_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "x_val = data[\"x_val\"]\n",
    "y_val = data[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: lscpu: command not found\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=4000)\n",
    "vec_train = vectorizer.fit_transform(x_train)\n",
    "vec_val = vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc = RandomForestClassifier()\n",
    "# svc = SVC()\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# rfc.fit(x, labels)\n",
    "# svc.fit(x, labels)\n",
    "lr = lr.fit(vec_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(vec_val)\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_val, y_pred=y_pred,)\n",
    "print(confusion_matrix)\n",
    "print(\"f1 score: \", metrics.f1_score(y_true=y_val, y_pred=y_pred), \"acc\", metrics.accuracy_score(y_true=y_val, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lr, \"models/tfidf_logistic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlr = joblib.load(\"models/tfidf_logistic.pkl\")\n",
    "newvec = joblib.load(\"models/tfidf_vec.pkl\")\n",
    "vec_val = newvec.transform(x_val)\n",
    "y_pred = lr.predict(vec_val)\n",
    "print(\"f1 score: \", metrics.f1_score(y_true=y_val, y_pred=y_pred), \"acc\", metrics.accuracy_score(y_true=y_val, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newvec = joblib.load(\"models/tfidf_vec.pkl\")\n",
    "tmp = np.array(['hello it is me'])\n",
    "result = newvec.transform(tmp)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(vectorizer, \"models/tfidf_vec.pkl\")\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "tmp_train = [x for x in x_train]\n",
    "max_len = len(tmp_train)\n",
    "new_x_train = []\n",
    "\n",
    "import math\n",
    "for i in range(int(math.ceil(max_len/bs))):\n",
    "    end = -1 if (i+1)*bs>max_len else (i+1)*bs\n",
    "    new_x_train.append(tmp_train[i*bs:end])\n",
    "\n",
    "print(len(new_x_train))\n",
    "print(len(new_x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_bert_train = []\n",
    "    tokenizer = BertTokenizer.from_pretrained('/Users/mccartney/Downloads/bert-base-uncased')\n",
    "    model = BertModel.from_pretrained(\"/Users/mccartney/Downloads/bert-base-uncased\")\n",
    "    for i, xi in enumerate(new_x_train):\n",
    "        encoded_input = tokenizer(xi, return_tensors='pt', padding=True)\n",
    "        output = model(**encoded_input)\n",
    "        x_bert_train.append(output.last_hidden_state[:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(x_train[-1], return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "tmp_out = output.last_hidden_state[0, 0, :]\n",
    "print(tmp_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bert_train = torch.cat(x_bert_train, dim=0)\n",
    "print(x_bert_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bert_train = x_bert_train.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_out = tmp_out.reshape(1, -1)\n",
    "print(x_bert_train.shape)\n",
    "print(tmp_out.shape)\n",
    "\n",
    "newx = [x_bert_train, tmp_out]\n",
    "newx = np.concatenate(newx)\n",
    "print(newx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_lr = LogisticRegression(max_iter=1000)\n",
    "bert_lr = bert_lr.fit(newx, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(bert_lr, \"./bert_base_uncased_logistic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_bert_val = []\n",
    "    for xi in tqdm.tqdm(x_val):\n",
    "        encoded_input = tokenizer(xi, return_tensors='pt')\n",
    "        encoded_input = {k:v for k, v in encoded_input.items()}\n",
    "        output = model(**encoded_input)\n",
    "        x_bert_val.append(output[0][:, 0, :])\n",
    "\n",
    "x_bert_val = torch.cat(x_bert_val, dim=0)\n",
    "x_bert_val = x_bert_val.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bert_lr.predict(x_bert_val)\n",
    "# print(confusion_matrix)\n",
    "print(\"f1 score: \", metrics.f1_score(y_true=y_val, y_pred=y_pred), \"acc\", metrics.accuracy_score(y_true=y_val, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/bert_train_vec.npy', newx)\n",
    "np.save('data/bert_val_vec.npy', x_bert_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bert_train = np.load('data/bert_train_vec.npy')\n",
    "x_bert_val = np.load('data/bert_val_vec.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load(\"models/tfidf_vec.pkl\")\n",
    "vec_val = vectorizer.transform(x_val)\n",
    "vec_train = vectorizer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.5802752293577982\n",
      "11 0.6009174311926605\n",
      "12 0.5986238532110092\n",
      "13 0.5963302752293578\n",
      "14 0.569954128440367\n",
      "15 0.6032110091743119\n",
      "16 0.5940366972477065\n",
      "17 0.5963302752293578\n",
      "18 0.5676605504587156\n",
      "19 0.5711009174311926\n",
      "20 0.555045871559633\n",
      "21 0.5768348623853211\n",
      "22 0.5722477064220184\n",
      "23 0.5951834862385321\n",
      "24 0.5940366972477065\n",
      "25 0.5676605504587156\n",
      "26 0.5676605504587156\n",
      "27 0.5837155963302753\n",
      "28 0.5630733944954128\n",
      "29 0.5779816513761468\n",
      "30 0.551605504587156\n",
      "31 0.5619266055045872\n",
      "32 0.5504587155963303\n",
      "33 0.5493119266055045\n",
      "34 0.5424311926605505\n",
      "35 0.5424311926605505\n",
      "36 0.5355504587155964\n",
      "37 0.5412844036697247\n",
      "38 0.5355504587155964\n",
      "39 0.5378440366972477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "result = {}\n",
    "for n in range(10,40):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n)  \n",
    "    neigh.fit(vec_train, y_train)  \n",
    "    y_pred = neigh.predict(vec_val)\n",
    "    acc = metrics.accuracy_score(y_true=y_val, y_pred=y_pred)\n",
    "\n",
    "    result[n]=acc\n",
    "\n",
    "for key in result:\n",
    "    print(key, result[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('knn_tfidf.npy', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 0.6032110091743119)\n"
     ]
    }
   ],
   "source": [
    "print(max(result.items(),key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/tfidf_knn.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=15)  \n",
    "neigh.fit(vec_train, y_train) \n",
    "joblib.dump(neigh, 'models/tfidf_knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(max_iter=1000)\n",
    "svm.fit(x_bert_train, y_train)\n",
    "y_pred = svm.predict(x_bert_val)\n",
    "print(confusion_matrix)\n",
    "print(\"f1 score: \", metrics.f1_score(y_true=y_val, y_pred=y_pred), \"acc\", metrics.accuracy_score(y_true=y_val, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(svm, \"./bert_base_uncased_svm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_train = [doc2vec.TaggedDocument(doc, [i]) for i, doc in enumerate(x_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec(doc_train, vector_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, \"./doc2vec.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_doc_val =  [model.infer_vector([doc])[None] for doc in x_val]\n",
    "vec_doc_val = np.concatenate(vec_doc_val, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_doc_train = [model.infer_vector([doc])[None] for doc in x_train]\n",
    "vec_doc_train = np.concatenate(vec_doc_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lr = LogisticRegression()\n",
    "doc_lr = doc_lr.fit(vec_doc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = doc_lr.predict(vec_doc_val)\n",
    "print(confusion_matrix)\n",
    "print(\"f1 score: \", metrics.f1_score(y_true=y_val, y_pred=y_pred), \"acc\", metrics.accuracy_score(y_true=y_val, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = joblib.load(\"models/tfidf_vec.pkl\")\n",
    "a = vectorizer.transform([\"hello you are good\"])\n",
    "\n",
    "lr = joblib.load(\"models/tfidf_logistic.pkl\")\n",
    "pred = lr.predict(a)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
